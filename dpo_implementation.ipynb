{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "model_output_dir='dpo_google/flan-t5-small'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, TrainingArguments\n",
    "from trl import DPOTrainer\n",
    "from datasets import Dataset\n",
    "\n",
    "from utils import remove_diacritics\n",
    "\n",
    "model_name = \"google/flan-t5-small\"\n",
    "LORA_RUN = False\n",
    "\n",
    "model_output_dir = f\"dpo_{model_name}\" \n",
    "model_output_dir += \"_lora\" if LORA_RUN else \"\"\n",
    "print(f\"{model_output_dir=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>rejected</th>\n",
       "      <th>chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>translate English to Romanian: I ate the cheese.</td>\n",
       "      <td>Am mâncat brânza.</td>\n",
       "      <td>Am mancat branza.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>translate English to Romanian: Today is Monday.</td>\n",
       "      <td>Astăzi este ziua de luni.</td>\n",
       "      <td>Astazi este ziua de luni.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>translate English to Romanian: Does he speak E...</td>\n",
       "      <td>Vorbeşte el limba engleză?</td>\n",
       "      <td>Vorbeste el limba engleza?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>translate English to Romanian: I'm sort of tired.</td>\n",
       "      <td>Sunt oarecum obosit.</td>\n",
       "      <td>Sunt oarecum obosit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>translate English to Romanian: I am indebted t...</td>\n",
       "      <td>Sunt îndatorat acestuia.</td>\n",
       "      <td>Sunt indatorat acestuia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15801</th>\n",
       "      <td>translate English to Romanian: It would be a d...</td>\n",
       "      <td>Ar fi o sarcină dificilă.</td>\n",
       "      <td>Ar fi o sarcina dificila.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15802</th>\n",
       "      <td>translate English to Romanian: I ate a burdock...</td>\n",
       "      <td>Am mâncat o tempura de rădăcini burdice.</td>\n",
       "      <td>Am mancat o tempura de radacini burdice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15803</th>\n",
       "      <td>translate English to Romanian: You say you've ...</td>\n",
       "      <td>Aţi spus că aţi văzut o UFO?</td>\n",
       "      <td>Ati spus ca ati vazut o UFO?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15804</th>\n",
       "      <td>translate English to Romanian: It's a good sen...</td>\n",
       "      <td>Oricum, este o frază bună.</td>\n",
       "      <td>Oricum, este o fraza buna.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15805</th>\n",
       "      <td>translate English to Romanian: I wouldn't want...</td>\n",
       "      <td>Nu aş dori să fiu judecător.</td>\n",
       "      <td>Nu as dori sa fiu judecator.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15806 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "0       translate English to Romanian: I ate the cheese.   \n",
       "1        translate English to Romanian: Today is Monday.   \n",
       "2      translate English to Romanian: Does he speak E...   \n",
       "3      translate English to Romanian: I'm sort of tired.   \n",
       "4      translate English to Romanian: I am indebted t...   \n",
       "...                                                  ...   \n",
       "15801  translate English to Romanian: It would be a d...   \n",
       "15802  translate English to Romanian: I ate a burdock...   \n",
       "15803  translate English to Romanian: You say you've ...   \n",
       "15804  translate English to Romanian: It's a good sen...   \n",
       "15805  translate English to Romanian: I wouldn't want...   \n",
       "\n",
       "                                       rejected  \\\n",
       "0                             Am mâncat brânza.   \n",
       "1                     Astăzi este ziua de luni.   \n",
       "2                    Vorbeşte el limba engleză?   \n",
       "3                          Sunt oarecum obosit.   \n",
       "4                      Sunt îndatorat acestuia.   \n",
       "...                                         ...   \n",
       "15801                 Ar fi o sarcină dificilă.   \n",
       "15802  Am mâncat o tempura de rădăcini burdice.   \n",
       "15803              Aţi spus că aţi văzut o UFO?   \n",
       "15804                Oricum, este o frază bună.   \n",
       "15805              Nu aş dori să fiu judecător.   \n",
       "\n",
       "                                         chosen  \n",
       "0                             Am mancat branza.  \n",
       "1                     Astazi este ziua de luni.  \n",
       "2                    Vorbeste el limba engleza?  \n",
       "3                          Sunt oarecum obosit.  \n",
       "4                      Sunt indatorat acestuia.  \n",
       "...                                         ...  \n",
       "15801                 Ar fi o sarcina dificila.  \n",
       "15802  Am mancat o tempura de radacini burdice.  \n",
       "15803              Ati spus ca ati vazut o UFO?  \n",
       "15804                Oricum, este o fraza buna.  \n",
       "15805              Nu as dori sa fiu judecator.  \n",
       "\n",
       "[15806 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/t5-small.csv\")\n",
    "\n",
    "df['chosen'] = df['translations'].apply(remove_diacritics)\n",
    "df[\"sentence\"] = df[\"sentence\"].apply(lambda x: f\"translate English to Romanian: {x}\")\n",
    "df = df.rename(columns={\"translations\": \"rejected\", \"sentence\": \"prompt\"})\n",
    "train_dataset = Dataset.from_dict({col: df[col].values.tolist() for col in df.columns})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "ref_model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is an experiment where the base layers are frozen\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'lm_head' not in name:\n",
    "#         param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python310\\lib\\site-packages\\trl\\trainer\\dpo_trainer.py:300: UserWarning: When using DPODataCollatorWithPadding with an encoder decoder architecture, you should set `max_target_length` in the DPOTrainer's init it will be set to `128` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "d:\\Python310\\lib\\site-packages\\trl\\trainer\\dpo_trainer.py:316: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da973498eb054c09ad1ca7b0703e80c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15806 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_output_dir,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-6,\n",
    "    num_train_epochs=2, \n",
    "    logging_dir=f\"{model_output_dir}/logs\",  \n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=ref_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    beta=0.1,\n",
    "    max_prompt_length=128,\n",
    "    max_length=1536,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7264428ed9184965bff31dab44b72195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/988 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6716, 'learning_rate': 9.898785425101213e-07, 'rewards/chosen': -0.05384952947497368, 'rewards/rejected': -0.11240199953317642, 'rewards/accuracies': 0.596875011920929, 'rewards/margins': 0.05855246260762215, 'logps/rejected': -25.946918487548828, 'logps/chosen': -43.5444221496582, 'logits/rejected': -9.902381896972656, 'logits/chosen': -9.617629051208496, 'epoch': 0.02}\n",
      "{'loss': 0.6814, 'learning_rate': 9.797570850202428e-07, 'rewards/chosen': -0.08459533751010895, 'rewards/rejected': -0.12115220725536346, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.03655686974525452, 'logps/rejected': -24.522146224975586, 'logps/chosen': -40.167640686035156, 'logits/rejected': -9.997121810913086, 'logits/chosen': -9.800909042358398, 'epoch': 0.04}\n",
      "{'loss': 0.6753, 'learning_rate': 9.696356275303643e-07, 'rewards/chosen': -0.045400477945804596, 'rewards/rejected': -0.09452062845230103, 'rewards/accuracies': 0.5718749761581421, 'rewards/margins': 0.04912015050649643, 'logps/rejected': -24.7596492767334, 'logps/chosen': -42.06877517700195, 'logits/rejected': -9.95449447631836, 'logits/chosen': -9.647397994995117, 'epoch': 0.06}\n",
      "{'loss': 0.6729, 'learning_rate': 9.595141700404857e-07, 'rewards/chosen': -0.05216966196894646, 'rewards/rejected': -0.10476148128509521, 'rewards/accuracies': 0.590624988079071, 'rewards/margins': 0.05259181931614876, 'logps/rejected': -25.363162994384766, 'logps/chosen': -41.74584197998047, 'logits/rejected': -9.856878280639648, 'logits/chosen': -9.662618637084961, 'epoch': 0.08}\n",
      "{'loss': 0.6699, 'learning_rate': 9.493927125506073e-07, 'rewards/chosen': -0.048844046890735626, 'rewards/rejected': -0.1111648678779602, 'rewards/accuracies': 0.606249988079071, 'rewards/margins': 0.06232081726193428, 'logps/rejected': -25.01216697692871, 'logps/chosen': -40.066871643066406, 'logits/rejected': -9.942319869995117, 'logits/chosen': -9.748082160949707, 'epoch': 0.1}\n",
      "{'loss': 0.6607, 'learning_rate': 9.392712550607287e-07, 'rewards/chosen': -0.038657624274492264, 'rewards/rejected': -0.12123938649892807, 'rewards/accuracies': 0.6312500238418579, 'rewards/margins': 0.08258175849914551, 'logps/rejected': -25.620376586914062, 'logps/chosen': -41.342201232910156, 'logits/rejected': -9.970375061035156, 'logits/chosen': -9.735715866088867, 'epoch': 0.12}\n",
      "{'loss': 0.6505, 'learning_rate': 9.291497975708502e-07, 'rewards/chosen': 0.0022511444985866547, 'rewards/rejected': -0.09933318197727203, 'rewards/accuracies': 0.6968749761581421, 'rewards/margins': 0.10158433020114899, 'logps/rejected': -23.5297794342041, 'logps/chosen': -41.37113952636719, 'logits/rejected': -9.900045394897461, 'logits/chosen': -9.615303993225098, 'epoch': 0.14}\n",
      "{'loss': 0.6557, 'learning_rate': 9.190283400809716e-07, 'rewards/chosen': -0.02013363502919674, 'rewards/rejected': -0.11102283000946045, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.09088918566703796, 'logps/rejected': -24.70644187927246, 'logps/chosen': -40.05567932128906, 'logits/rejected': -9.849782943725586, 'logits/chosen': -9.636857986450195, 'epoch': 0.16}\n",
      "{'loss': 0.6421, 'learning_rate': 9.08906882591093e-07, 'rewards/chosen': 0.002945943269878626, 'rewards/rejected': -0.11877211183309555, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.12171804904937744, 'logps/rejected': -26.094379425048828, 'logps/chosen': -41.57624053955078, 'logits/rejected': -9.748888969421387, 'logits/chosen': -9.558448791503906, 'epoch': 0.18}\n",
      "{'loss': 0.6401, 'learning_rate': 8.987854251012146e-07, 'rewards/chosen': -0.001023189746774733, 'rewards/rejected': -0.12582913041114807, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.12480594962835312, 'logps/rejected': -24.85854148864746, 'logps/chosen': -40.63358688354492, 'logits/rejected': -9.924518585205078, 'logits/chosen': -9.705245018005371, 'epoch': 0.2}\n",
      "{'loss': 0.6167, 'learning_rate': 8.88663967611336e-07, 'rewards/chosen': 0.04568907991051674, 'rewards/rejected': -0.13098496198654175, 'rewards/accuracies': 0.784375011920929, 'rewards/margins': 0.1766740381717682, 'logps/rejected': -26.498743057250977, 'logps/chosen': -42.73931884765625, 'logits/rejected': -9.79609489440918, 'logits/chosen': -9.57807731628418, 'epoch': 0.22}\n",
      "{'loss': 0.6301, 'learning_rate': 8.785425101214574e-07, 'rewards/chosen': 0.010623353533446789, 'rewards/rejected': -0.13434147834777832, 'rewards/accuracies': 0.7406250238418579, 'rewards/margins': 0.14496484398841858, 'logps/rejected': -24.822603225708008, 'logps/chosen': -40.64787673950195, 'logits/rejected': -9.987726211547852, 'logits/chosen': -9.675047874450684, 'epoch': 0.24}\n",
      "{'loss': 0.6232, 'learning_rate': 8.684210526315789e-07, 'rewards/chosen': 0.031192678958177567, 'rewards/rejected': -0.13006630539894104, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1612590104341507, 'logps/rejected': -25.130510330200195, 'logps/chosen': -40.98149108886719, 'logits/rejected': -9.70596981048584, 'logits/chosen': -9.561800003051758, 'epoch': 0.26}\n",
      "{'loss': 0.631, 'learning_rate': 8.582995951417004e-07, 'rewards/chosen': 0.017697017639875412, 'rewards/rejected': -0.12920382618904114, 'rewards/accuracies': 0.6937500238418579, 'rewards/margins': 0.14690086245536804, 'logps/rejected': -26.238391876220703, 'logps/chosen': -41.50358963012695, 'logits/rejected': -9.825103759765625, 'logits/chosen': -9.612555503845215, 'epoch': 0.28}\n",
      "{'loss': 0.6259, 'learning_rate': 8.481781376518218e-07, 'rewards/chosen': 0.028212502598762512, 'rewards/rejected': -0.12889263033866882, 'rewards/accuracies': 0.734375, 'rewards/margins': 0.15710513293743134, 'logps/rejected': -25.433307647705078, 'logps/chosen': -39.7402458190918, 'logits/rejected': -9.74793815612793, 'logits/chosen': -9.463193893432617, 'epoch': 0.3}\n",
      "{'loss': 0.618, 'learning_rate': 8.380566801619433e-07, 'rewards/chosen': 0.027535920962691307, 'rewards/rejected': -0.14953455328941345, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.1770704686641693, 'logps/rejected': -26.966228485107422, 'logps/chosen': -42.04524612426758, 'logits/rejected': -9.637591361999512, 'logits/chosen': -9.385147094726562, 'epoch': 0.32}\n",
      "{'loss': 0.6186, 'learning_rate': 8.279352226720648e-07, 'rewards/chosen': 0.029796991497278214, 'rewards/rejected': -0.14302034676074982, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.17281731963157654, 'logps/rejected': -25.873315811157227, 'logps/chosen': -40.045982360839844, 'logits/rejected': -9.732522964477539, 'logits/chosen': -9.560128211975098, 'epoch': 0.34}\n",
      "{'loss': 0.5978, 'learning_rate': 8.178137651821862e-07, 'rewards/chosen': 0.06482086330652237, 'rewards/rejected': -0.16061519086360931, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 0.2254360467195511, 'logps/rejected': -26.12453842163086, 'logps/chosen': -41.57782745361328, 'logits/rejected': -9.709246635437012, 'logits/chosen': -9.441214561462402, 'epoch': 0.36}\n",
      "{'loss': 0.6229, 'learning_rate': 8.076923076923077e-07, 'rewards/chosen': 0.0445592999458313, 'rewards/rejected': -0.12215028703212738, 'rewards/accuracies': 0.75, 'rewards/margins': 0.16670958697795868, 'logps/rejected': -24.784305572509766, 'logps/chosen': -37.79393768310547, 'logits/rejected': -9.655183792114258, 'logits/chosen': -9.381279945373535, 'epoch': 0.38}\n",
      "{'loss': 0.5919, 'learning_rate': 7.97570850202429e-07, 'rewards/chosen': 0.07108598947525024, 'rewards/rejected': -0.16126307845115662, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.23234908282756805, 'logps/rejected': -26.16963768005371, 'logps/chosen': -41.60266876220703, 'logits/rejected': -9.650385856628418, 'logits/chosen': -9.4197359085083, 'epoch': 0.4}\n",
      "{'loss': 0.6032, 'learning_rate': 7.874493927125506e-07, 'rewards/chosen': 0.06484262645244598, 'rewards/rejected': -0.14599159359931946, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.21083423495292664, 'logps/rejected': -23.919776916503906, 'logps/chosen': -37.942588806152344, 'logits/rejected': -9.644972801208496, 'logits/chosen': -9.388154029846191, 'epoch': 0.43}\n",
      "{'loss': 0.6048, 'learning_rate': 7.77327935222672e-07, 'rewards/chosen': 0.06402786821126938, 'rewards/rejected': -0.1393924206495285, 'rewards/accuracies': 0.778124988079071, 'rewards/margins': 0.20342031121253967, 'logps/rejected': -24.54702377319336, 'logps/chosen': -38.802391052246094, 'logits/rejected': -9.688687324523926, 'logits/chosen': -9.452433586120605, 'epoch': 0.45}\n",
      "{'loss': 0.5888, 'learning_rate': 7.672064777327934e-07, 'rewards/chosen': 0.08638431876897812, 'rewards/rejected': -0.15573379397392273, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 0.24211809039115906, 'logps/rejected': -25.499298095703125, 'logps/chosen': -40.249786376953125, 'logits/rejected': -9.728384017944336, 'logits/chosen': -9.48111629486084, 'epoch': 0.47}\n",
      "{'loss': 0.5863, 'learning_rate': 7.57085020242915e-07, 'rewards/chosen': 0.0812370553612709, 'rewards/rejected': -0.17093054950237274, 'rewards/accuracies': 0.784375011920929, 'rewards/margins': 0.25216758251190186, 'logps/rejected': -27.167144775390625, 'logps/chosen': -40.762386322021484, 'logits/rejected': -9.759917259216309, 'logits/chosen': -9.496285438537598, 'epoch': 0.49}\n",
      "{'loss': 0.5749, 'learning_rate': 7.469635627530364e-07, 'rewards/chosen': 0.09973450005054474, 'rewards/rejected': -0.17625625431537628, 'rewards/accuracies': 0.828125, 'rewards/margins': 0.27599072456359863, 'logps/rejected': -24.131792068481445, 'logps/chosen': -39.911346435546875, 'logits/rejected': -9.736117362976074, 'logits/chosen': -9.48062515258789, 'epoch': 0.51}\n",
      "{'loss': 0.5713, 'learning_rate': 7.368421052631578e-07, 'rewards/chosen': 0.10521336644887924, 'rewards/rejected': -0.17831160128116608, 'rewards/accuracies': 0.84375, 'rewards/margins': 0.2835249900817871, 'logps/rejected': -24.583044052124023, 'logps/chosen': -38.78313064575195, 'logits/rejected': -9.860586166381836, 'logits/chosen': -9.614069938659668, 'epoch': 0.53}\n",
      "{'loss': 0.5812, 'learning_rate': 7.267206477732794e-07, 'rewards/chosen': 0.08236853778362274, 'rewards/rejected': -0.18221178650856018, 'rewards/accuracies': 0.796875, 'rewards/margins': 0.2645803391933441, 'logps/rejected': -26.309551239013672, 'logps/chosen': -40.194801330566406, 'logits/rejected': -9.53105354309082, 'logits/chosen': -9.36777400970459, 'epoch': 0.55}\n",
      "{'loss': 0.5673, 'learning_rate': 7.165991902834008e-07, 'rewards/chosen': 0.10310405492782593, 'rewards/rejected': -0.1938173919916153, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 0.29692143201828003, 'logps/rejected': -26.4753475189209, 'logps/chosen': -41.593910217285156, 'logits/rejected': -9.583213806152344, 'logits/chosen': -9.385503768920898, 'epoch': 0.57}\n",
      "{'loss': 0.5766, 'learning_rate': 7.064777327935222e-07, 'rewards/chosen': 0.09992137551307678, 'rewards/rejected': -0.17252573370933533, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 0.2724471092224121, 'logps/rejected': -24.90472412109375, 'logps/chosen': -39.1053466796875, 'logits/rejected': -9.758868217468262, 'logits/chosen': -9.57814884185791, 'epoch': 0.59}\n",
      "{'loss': 0.5813, 'learning_rate': 6.963562753036437e-07, 'rewards/chosen': 0.09072884172201157, 'rewards/rejected': -0.17134802043437958, 'rewards/accuracies': 0.809374988079071, 'rewards/margins': 0.26207688450813293, 'logps/rejected': -25.217126846313477, 'logps/chosen': -38.85822296142578, 'logits/rejected': -9.621362686157227, 'logits/chosen': -9.35136604309082, 'epoch': 0.61}\n",
      "{'loss': 0.5691, 'learning_rate': 6.862348178137652e-07, 'rewards/chosen': 0.08768445998430252, 'rewards/rejected': -0.2104015350341797, 'rewards/accuracies': 0.8218749761581421, 'rewards/margins': 0.2980859875679016, 'logps/rejected': -25.563434600830078, 'logps/chosen': -39.75485610961914, 'logits/rejected': -9.78215217590332, 'logits/chosen': -9.565683364868164, 'epoch': 0.63}\n",
      "{'loss': 0.5672, 'learning_rate': 6.761133603238867e-07, 'rewards/chosen': 0.08861309289932251, 'rewards/rejected': -0.2096472531557083, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 0.29826033115386963, 'logps/rejected': -26.72430419921875, 'logps/chosen': -40.07706832885742, 'logits/rejected': -9.582114219665527, 'logits/chosen': -9.400562286376953, 'epoch': 0.65}\n",
      "{'loss': 0.5601, 'learning_rate': 6.65991902834008e-07, 'rewards/chosen': 0.09052447974681854, 'rewards/rejected': -0.22397954761981964, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 0.3145039975643158, 'logps/rejected': -26.26125144958496, 'logps/chosen': -39.93810272216797, 'logits/rejected': -9.616535186767578, 'logits/chosen': -9.436724662780762, 'epoch': 0.67}\n",
      "{'loss': 0.5463, 'learning_rate': 6.558704453441295e-07, 'rewards/chosen': 0.12299083173274994, 'rewards/rejected': -0.22609266638755798, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 0.3490835130214691, 'logps/rejected': -27.102331161499023, 'logps/chosen': -41.662384033203125, 'logits/rejected': -9.558703422546387, 'logits/chosen': -9.340738296508789, 'epoch': 0.69}\n",
      "{'loss': 0.5602, 'learning_rate': 6.45748987854251e-07, 'rewards/chosen': 0.11190678179264069, 'rewards/rejected': -0.2088203877210617, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.3207271695137024, 'logps/rejected': -26.113901138305664, 'logps/chosen': -40.118778228759766, 'logits/rejected': -9.709665298461914, 'logits/chosen': -9.481097221374512, 'epoch': 0.71}\n",
      "{'loss': 0.5535, 'learning_rate': 6.356275303643724e-07, 'rewards/chosen': 0.1198873296380043, 'rewards/rejected': -0.21550226211547852, 'rewards/accuracies': 0.8531249761581421, 'rewards/margins': 0.3353895843029022, 'logps/rejected': -26.5992488861084, 'logps/chosen': -40.865760803222656, 'logits/rejected': -9.559968948364258, 'logits/chosen': -9.334783554077148, 'epoch': 0.73}\n",
      "{'loss': 0.5578, 'learning_rate': 6.255060728744938e-07, 'rewards/chosen': 0.11209051311016083, 'rewards/rejected': -0.21673305332660675, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.3288235664367676, 'logps/rejected': -25.91324806213379, 'logps/chosen': -39.557884216308594, 'logits/rejected': -9.635149002075195, 'logits/chosen': -9.494714736938477, 'epoch': 0.75}\n",
      "{'loss': 0.5443, 'learning_rate': 6.153846153846154e-07, 'rewards/chosen': 0.12736019492149353, 'rewards/rejected': -0.2324827015399933, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 0.35984286665916443, 'logps/rejected': -27.2540283203125, 'logps/chosen': -40.957664489746094, 'logits/rejected': -9.577268600463867, 'logits/chosen': -9.362295150756836, 'epoch': 0.77}\n",
      "{'loss': 0.5445, 'learning_rate': 6.052631578947368e-07, 'rewards/chosen': 0.11781759560108185, 'rewards/rejected': -0.24168618023395538, 'rewards/accuracies': 0.890625, 'rewards/margins': 0.35950377583503723, 'logps/rejected': -26.6704044342041, 'logps/chosen': -41.08185577392578, 'logits/rejected': -9.51030158996582, 'logits/chosen': -9.289445877075195, 'epoch': 0.79}\n",
      "{'loss': 0.5511, 'learning_rate': 5.951417004048582e-07, 'rewards/chosen': 0.10730186849832535, 'rewards/rejected': -0.2322021722793579, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 0.33950406312942505, 'logps/rejected': -25.206729888916016, 'logps/chosen': -38.619972229003906, 'logits/rejected': -9.570545196533203, 'logits/chosen': -9.400074005126953, 'epoch': 0.81}\n",
      "{'loss': 0.5482, 'learning_rate': 5.850202429149798e-07, 'rewards/chosen': 0.11218899488449097, 'rewards/rejected': -0.2341729700565338, 'rewards/accuracies': 0.8531249761581421, 'rewards/margins': 0.3463619351387024, 'logps/rejected': -25.712749481201172, 'logps/chosen': -39.32197189331055, 'logits/rejected': -9.364469528198242, 'logits/chosen': -9.196014404296875, 'epoch': 0.83}\n",
      "{'loss': 0.5384, 'learning_rate': 5.748987854251012e-07, 'rewards/chosen': 0.12519799172878265, 'rewards/rejected': -0.2533988356590271, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 0.37859684228897095, 'logps/rejected': -24.786794662475586, 'logps/chosen': -39.43760299682617, 'logits/rejected': -9.725772857666016, 'logits/chosen': -9.459466934204102, 'epoch': 0.85}\n",
      "{'loss': 0.5375, 'learning_rate': 5.647773279352226e-07, 'rewards/chosen': 0.13075821101665497, 'rewards/rejected': -0.2511184513568878, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 0.3818766176700592, 'logps/rejected': -26.1351261138916, 'logps/chosen': -40.82589340209961, 'logits/rejected': -9.493370056152344, 'logits/chosen': -9.343955039978027, 'epoch': 0.87}\n",
      "{'loss': 0.5473, 'learning_rate': 5.546558704453442e-07, 'rewards/chosen': 0.12435624748468399, 'rewards/rejected': -0.22873440384864807, 'rewards/accuracies': 0.8343750238418579, 'rewards/margins': 0.3530906140804291, 'logps/rejected': -25.924545288085938, 'logps/chosen': -38.12598419189453, 'logits/rejected': -9.488188743591309, 'logits/chosen': -9.380146026611328, 'epoch': 0.89}\n",
      "{'loss': 0.5491, 'learning_rate': 5.445344129554656e-07, 'rewards/chosen': 0.12173371016979218, 'rewards/rejected': -0.22799289226531982, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 0.3497266173362732, 'logps/rejected': -25.445154190063477, 'logps/chosen': -39.21445083618164, 'logits/rejected': -9.555423736572266, 'logits/chosen': -9.363980293273926, 'epoch': 0.91}\n",
      "{'loss': 0.5398, 'learning_rate': 5.34412955465587e-07, 'rewards/chosen': 0.12111127376556396, 'rewards/rejected': -0.2549108862876892, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.3760221004486084, 'logps/rejected': -26.974130630493164, 'logps/chosen': -40.55778503417969, 'logits/rejected': -9.505353927612305, 'logits/chosen': -9.327993392944336, 'epoch': 0.93}\n",
      "{'loss': 0.5363, 'learning_rate': 5.242914979757084e-07, 'rewards/chosen': 0.13233359158039093, 'rewards/rejected': -0.247615247964859, 'rewards/accuracies': 0.8656250238418579, 'rewards/margins': 0.37994885444641113, 'logps/rejected': -26.0573673248291, 'logps/chosen': -39.05356216430664, 'logits/rejected': -9.4949951171875, 'logits/chosen': -9.294243812561035, 'epoch': 0.95}\n",
      "{'loss': 0.5372, 'learning_rate': 5.141700404858299e-07, 'rewards/chosen': 0.12461881339550018, 'rewards/rejected': -0.2591349184513092, 'rewards/accuracies': 0.846875011920929, 'rewards/margins': 0.3837537169456482, 'logps/rejected': -26.042346954345703, 'logps/chosen': -39.09869384765625, 'logits/rejected': -9.482117652893066, 'logits/chosen': -9.282559394836426, 'epoch': 0.97}\n",
      "{'loss': 0.5382, 'learning_rate': 5.040485829959514e-07, 'rewards/chosen': 0.11197805404663086, 'rewards/rejected': -0.27659833431243896, 'rewards/accuracies': 0.840624988079071, 'rewards/margins': 0.3885764479637146, 'logps/rejected': -25.97137451171875, 'logps/chosen': -38.661888122558594, 'logits/rejected': -9.461438179016113, 'logits/chosen': -9.218358039855957, 'epoch': 0.99}\n",
      "{'loss': 0.5192, 'learning_rate': 4.939271255060728e-07, 'rewards/chosen': 0.16174063086509705, 'rewards/rejected': -0.26982855796813965, 'rewards/accuracies': 0.8979166746139526, 'rewards/margins': 0.4315691590309143, 'logps/rejected': -27.424758911132812, 'logps/chosen': -41.04251480102539, 'logits/rejected': -9.552531242370605, 'logits/chosen': -9.411884307861328, 'epoch': 1.01}\n",
      "{'loss': 0.5341, 'learning_rate': 4.838056680161944e-07, 'rewards/chosen': 0.1321696788072586, 'rewards/rejected': -0.2587820589542389, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 0.3909517228603363, 'logps/rejected': -26.32149887084961, 'logps/chosen': -39.004798889160156, 'logits/rejected': -9.539857864379883, 'logits/chosen': -9.343778610229492, 'epoch': 1.03}\n",
      "{'loss': 0.527, 'learning_rate': 4.7368421052631574e-07, 'rewards/chosen': 0.13233400881290436, 'rewards/rejected': -0.2741278111934662, 'rewards/accuracies': 0.875, 'rewards/margins': 0.40646180510520935, 'logps/rejected': -26.732433319091797, 'logps/chosen': -40.045799255371094, 'logits/rejected': -9.523117065429688, 'logits/chosen': -9.31213092803955, 'epoch': 1.05}\n",
      "{'loss': 0.5181, 'learning_rate': 4.635627530364372e-07, 'rewards/chosen': 0.15587358176708221, 'rewards/rejected': -0.2757754623889923, 'rewards/accuracies': 0.8843749761581421, 'rewards/margins': 0.43164902925491333, 'logps/rejected': -25.950963973999023, 'logps/chosen': -39.351051330566406, 'logits/rejected': -9.503405570983887, 'logits/chosen': -9.26386547088623, 'epoch': 1.07}\n",
      "{'loss': 0.5192, 'learning_rate': 4.534412955465587e-07, 'rewards/chosen': 0.13622350990772247, 'rewards/rejected': -0.2877820134162903, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 0.42400550842285156, 'logps/rejected': -27.02388572692871, 'logps/chosen': -40.29315185546875, 'logits/rejected': -9.447985649108887, 'logits/chosen': -9.294548034667969, 'epoch': 1.09}\n",
      "{'loss': 0.5419, 'learning_rate': 4.433198380566802e-07, 'rewards/chosen': 0.1225636750459671, 'rewards/rejected': -0.2417844533920288, 'rewards/accuracies': 0.871874988079071, 'rewards/margins': 0.3643481135368347, 'logps/rejected': -26.020374298095703, 'logps/chosen': -37.72688674926758, 'logits/rejected': -9.450273513793945, 'logits/chosen': -9.295011520385742, 'epoch': 1.11}\n",
      "{'loss': 0.5341, 'learning_rate': 4.3319838056680156e-07, 'rewards/chosen': 0.1142861396074295, 'rewards/rejected': -0.27953097224235535, 'rewards/accuracies': 0.846875011920929, 'rewards/margins': 0.39381712675094604, 'logps/rejected': -26.55196189880371, 'logps/chosen': -38.52570343017578, 'logits/rejected': -9.422887802124023, 'logits/chosen': -9.247547149658203, 'epoch': 1.13}\n",
      "{'loss': 0.5193, 'learning_rate': 4.2307692307692304e-07, 'rewards/chosen': 0.13472270965576172, 'rewards/rejected': -0.2929007411003113, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 0.427623450756073, 'logps/rejected': -27.113855361938477, 'logps/chosen': -38.93334197998047, 'logits/rejected': -9.416862487792969, 'logits/chosen': -9.336373329162598, 'epoch': 1.15}\n",
      "{'loss': 0.5149, 'learning_rate': 4.129554655870445e-07, 'rewards/chosen': 0.1301509439945221, 'rewards/rejected': -0.3117721974849701, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 0.4419231414794922, 'logps/rejected': -25.840408325195312, 'logps/chosen': -38.50248336791992, 'logits/rejected': -9.546859741210938, 'logits/chosen': -9.330400466918945, 'epoch': 1.17}\n",
      "{'loss': 0.5097, 'learning_rate': 4.02834008097166e-07, 'rewards/chosen': 0.16575667262077332, 'rewards/rejected': -0.29090172052383423, 'rewards/accuracies': 0.909375011920929, 'rewards/margins': 0.45665836334228516, 'logps/rejected': -27.074665069580078, 'logps/chosen': -39.230770111083984, 'logits/rejected': -9.480941772460938, 'logits/chosen': -9.311036109924316, 'epoch': 1.19}\n",
      "{'loss': 0.5185, 'learning_rate': 3.9271255060728743e-07, 'rewards/chosen': 0.12091086804866791, 'rewards/rejected': -0.3217891454696655, 'rewards/accuracies': 0.8531249761581421, 'rewards/margins': 0.44269999861717224, 'logps/rejected': -27.32669448852539, 'logps/chosen': -39.70811080932617, 'logits/rejected': -9.457932472229004, 'logits/chosen': -9.282538414001465, 'epoch': 1.21}\n",
      "{'loss': 0.5087, 'learning_rate': 3.825910931174089e-07, 'rewards/chosen': 0.17570360004901886, 'rewards/rejected': -0.293060839176178, 'rewards/accuracies': 0.890625, 'rewards/margins': 0.46876439452171326, 'logps/rejected': -26.836267471313477, 'logps/chosen': -40.213592529296875, 'logits/rejected': -9.353952407836914, 'logits/chosen': -9.181753158569336, 'epoch': 1.23}\n",
      "{'loss': 0.5143, 'learning_rate': 3.7246963562753034e-07, 'rewards/chosen': 0.13796880841255188, 'rewards/rejected': -0.3122329115867615, 'rewards/accuracies': 0.8531249761581421, 'rewards/margins': 0.45020174980163574, 'logps/rejected': -27.570709228515625, 'logps/chosen': -41.46837615966797, 'logits/rejected': -9.416994094848633, 'logits/chosen': -9.213632583618164, 'epoch': 1.26}\n",
      "{'loss': 0.5104, 'learning_rate': 3.6234817813765177e-07, 'rewards/chosen': 0.13714522123336792, 'rewards/rejected': -0.316610723733902, 'rewards/accuracies': 0.903124988079071, 'rewards/margins': 0.4537559449672699, 'logps/rejected': -25.011003494262695, 'logps/chosen': -37.95703125, 'logits/rejected': -9.60506820678711, 'logits/chosen': -9.433956146240234, 'epoch': 1.28}\n",
      "{'loss': 0.5104, 'learning_rate': 3.5222672064777325e-07, 'rewards/chosen': 0.15807245671749115, 'rewards/rejected': -0.30112800002098083, 'rewards/accuracies': 0.878125011920929, 'rewards/margins': 0.4592004418373108, 'logps/rejected': -26.770156860351562, 'logps/chosen': -38.998878479003906, 'logits/rejected': -9.548731803894043, 'logits/chosen': -9.381303787231445, 'epoch': 1.3}\n",
      "{'loss': 0.5108, 'learning_rate': 3.4210526315789473e-07, 'rewards/chosen': 0.15493586659431458, 'rewards/rejected': -0.30683234333992004, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 0.461768239736557, 'logps/rejected': -28.113250732421875, 'logps/chosen': -40.16069412231445, 'logits/rejected': -9.385279655456543, 'logits/chosen': -9.216917037963867, 'epoch': 1.32}\n",
      "{'loss': 0.4995, 'learning_rate': 3.319838056680162e-07, 'rewards/chosen': 0.14301937818527222, 'rewards/rejected': -0.34518367052078247, 'rewards/accuracies': 0.903124988079071, 'rewards/margins': 0.4882030487060547, 'logps/rejected': -28.309589385986328, 'logps/chosen': -40.721309661865234, 'logits/rejected': -9.371957778930664, 'logits/chosen': -9.243317604064941, 'epoch': 1.34}\n",
      "{'loss': 0.5189, 'learning_rate': 3.2186234817813764e-07, 'rewards/chosen': 0.10931549221277237, 'rewards/rejected': -0.3320840001106262, 'rewards/accuracies': 0.8343750238418579, 'rewards/margins': 0.441399484872818, 'logps/rejected': -27.164928436279297, 'logps/chosen': -38.414127349853516, 'logits/rejected': -9.444953918457031, 'logits/chosen': -9.265098571777344, 'epoch': 1.36}\n",
      "{'loss': 0.5019, 'learning_rate': 3.117408906882591e-07, 'rewards/chosen': 0.13697907328605652, 'rewards/rejected': -0.35024383664131165, 'rewards/accuracies': 0.875, 'rewards/margins': 0.48722290992736816, 'logps/rejected': -27.352962493896484, 'logps/chosen': -40.268768310546875, 'logits/rejected': -9.45052719116211, 'logits/chosen': -9.292325019836426, 'epoch': 1.38}\n",
      "{'loss': 0.4881, 'learning_rate': 3.0161943319838055e-07, 'rewards/chosen': 0.15017452836036682, 'rewards/rejected': -0.3633028268814087, 'rewards/accuracies': 0.909375011920929, 'rewards/margins': 0.5134773850440979, 'logps/rejected': -27.230648040771484, 'logps/chosen': -39.397804260253906, 'logits/rejected': -9.513107299804688, 'logits/chosen': -9.312649726867676, 'epoch': 1.4}\n",
      "{'loss': 0.5039, 'learning_rate': 2.91497975708502e-07, 'rewards/chosen': 0.13235700130462646, 'rewards/rejected': -0.3492458164691925, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 0.48160281777381897, 'logps/rejected': -29.306896209716797, 'logps/chosen': -41.118934631347656, 'logits/rejected': -9.385513305664062, 'logits/chosen': -9.216277122497559, 'epoch': 1.42}\n",
      "{'loss': 0.4921, 'learning_rate': 2.8137651821862346e-07, 'rewards/chosen': 0.16121956706047058, 'rewards/rejected': -0.35461774468421936, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 0.5158373117446899, 'logps/rejected': -27.808197021484375, 'logps/chosen': -40.75949478149414, 'logits/rejected': -9.396642684936523, 'logits/chosen': -9.18846321105957, 'epoch': 1.44}\n",
      "{'loss': 0.5035, 'learning_rate': 2.7125506072874494e-07, 'rewards/chosen': 0.1438814252614975, 'rewards/rejected': -0.3329337239265442, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 0.4768151342868805, 'logps/rejected': -27.397090911865234, 'logps/chosen': -39.7236213684082, 'logits/rejected': -9.44560432434082, 'logits/chosen': -9.234708786010742, 'epoch': 1.46}\n",
      "{'loss': 0.5006, 'learning_rate': 2.611336032388664e-07, 'rewards/chosen': 0.14791451394557953, 'rewards/rejected': -0.3478557765483856, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 0.49577027559280396, 'logps/rejected': -29.27268409729004, 'logps/chosen': -42.665794372558594, 'logits/rejected': -9.283113479614258, 'logits/chosen': -9.162796974182129, 'epoch': 1.48}\n",
      "{'loss': 0.5033, 'learning_rate': 2.5101214574898785e-07, 'rewards/chosen': 0.1424359679222107, 'rewards/rejected': -0.33683791756629944, 'rewards/accuracies': 0.871874988079071, 'rewards/margins': 0.47927388548851013, 'logps/rejected': -26.4215145111084, 'logps/chosen': -38.98888397216797, 'logits/rejected': -9.369282722473145, 'logits/chosen': -9.253717422485352, 'epoch': 1.5}\n",
      "{'loss': 0.4979, 'learning_rate': 2.408906882591093e-07, 'rewards/chosen': 0.1446843147277832, 'rewards/rejected': -0.35262879729270935, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 0.49731311202049255, 'logps/rejected': -26.02821922302246, 'logps/chosen': -37.89563751220703, 'logits/rejected': -9.574898719787598, 'logits/chosen': -9.381484985351562, 'epoch': 1.52}\n",
      "{'loss': 0.4953, 'learning_rate': 2.3076923076923078e-07, 'rewards/chosen': 0.14074914157390594, 'rewards/rejected': -0.358420193195343, 'rewards/accuracies': 0.8843749761581421, 'rewards/margins': 0.49916934967041016, 'logps/rejected': -26.841556549072266, 'logps/chosen': -38.82257080078125, 'logits/rejected': -9.299992561340332, 'logits/chosen': -9.11568832397461, 'epoch': 1.54}\n",
      "{'loss': 0.4781, 'learning_rate': 2.206477732793522e-07, 'rewards/chosen': 0.19921869039535522, 'rewards/rejected': -0.36153966188430786, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 0.5607582926750183, 'logps/rejected': -28.024761199951172, 'logps/chosen': -42.082069396972656, 'logits/rejected': -9.441720962524414, 'logits/chosen': -9.246870040893555, 'epoch': 1.56}\n",
      "{'loss': 0.4935, 'learning_rate': 2.1052631578947366e-07, 'rewards/chosen': 0.14789657294750214, 'rewards/rejected': -0.36188527941703796, 'rewards/accuracies': 0.878125011920929, 'rewards/margins': 0.5097818970680237, 'logps/rejected': -28.066808700561523, 'logps/chosen': -41.13486862182617, 'logits/rejected': -9.520465850830078, 'logits/chosen': -9.29522705078125, 'epoch': 1.58}\n",
      "{'loss': 0.4982, 'learning_rate': 2.0040485829959514e-07, 'rewards/chosen': 0.136850968003273, 'rewards/rejected': -0.3633444607257843, 'rewards/accuracies': 0.878125011920929, 'rewards/margins': 0.5001953840255737, 'logps/rejected': -26.520071029663086, 'logps/chosen': -38.247623443603516, 'logits/rejected': -9.531408309936523, 'logits/chosen': -9.370031356811523, 'epoch': 1.6}\n",
      "{'loss': 0.4961, 'learning_rate': 1.9028340080971657e-07, 'rewards/chosen': 0.15597769618034363, 'rewards/rejected': -0.34850403666496277, 'rewards/accuracies': 0.8968750238418579, 'rewards/margins': 0.5044817328453064, 'logps/rejected': -28.66629981994629, 'logps/chosen': -41.3690185546875, 'logits/rejected': -9.296616554260254, 'logits/chosen': -9.121231079101562, 'epoch': 1.62}\n",
      "{'loss': 0.5087, 'learning_rate': 1.8016194331983805e-07, 'rewards/chosen': 0.11392185837030411, 'rewards/rejected': -0.34354954957962036, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 0.45747143030166626, 'logps/rejected': -27.893600463867188, 'logps/chosen': -38.221553802490234, 'logits/rejected': -9.448458671569824, 'logits/chosen': -9.299958229064941, 'epoch': 1.64}\n",
      "{'loss': 0.5128, 'learning_rate': 1.700404858299595e-07, 'rewards/chosen': 0.10866844654083252, 'rewards/rejected': -0.3473537862300873, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 0.456022173166275, 'logps/rejected': -26.556926727294922, 'logps/chosen': -37.29340744018555, 'logits/rejected': -9.393438339233398, 'logits/chosen': -9.247556686401367, 'epoch': 1.66}\n",
      "{'loss': 0.4908, 'learning_rate': 1.5991902834008096e-07, 'rewards/chosen': 0.13959407806396484, 'rewards/rejected': -0.3856111168861389, 'rewards/accuracies': 0.8843749761581421, 'rewards/margins': 0.5252052545547485, 'logps/rejected': -27.788610458374023, 'logps/chosen': -40.79447555541992, 'logits/rejected': -9.385858535766602, 'logits/chosen': -9.215873718261719, 'epoch': 1.68}\n",
      "{'loss': 0.4825, 'learning_rate': 1.4979757085020242e-07, 'rewards/chosen': 0.15150687098503113, 'rewards/rejected': -0.3838464617729187, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 0.5353533029556274, 'logps/rejected': -27.457599639892578, 'logps/chosen': -39.309268951416016, 'logits/rejected': -9.365903854370117, 'logits/chosen': -9.233256340026855, 'epoch': 1.7}\n",
      "{'loss': 0.4963, 'learning_rate': 1.396761133603239e-07, 'rewards/chosen': 0.12350808084011078, 'rewards/rejected': -0.37313494086265564, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 0.4966430068016052, 'logps/rejected': -27.57168197631836, 'logps/chosen': -38.98291015625, 'logits/rejected': -9.410362243652344, 'logits/chosen': -9.201211929321289, 'epoch': 1.72}\n",
      "{'loss': 0.5093, 'learning_rate': 1.2955465587044535e-07, 'rewards/chosen': 0.11254537105560303, 'rewards/rejected': -0.353853702545166, 'rewards/accuracies': 0.846875011920929, 'rewards/margins': 0.46639904379844666, 'logps/rejected': -26.955806732177734, 'logps/chosen': -38.40994644165039, 'logits/rejected': -9.47176742553711, 'logits/chosen': -9.249853134155273, 'epoch': 1.74}\n",
      "{'loss': 0.4882, 'learning_rate': 1.194331983805668e-07, 'rewards/chosen': 0.1522688865661621, 'rewards/rejected': -0.3763597011566162, 'rewards/accuracies': 0.921875, 'rewards/margins': 0.5286286473274231, 'logps/rejected': -28.307443618774414, 'logps/chosen': -40.6124267578125, 'logits/rejected': -9.389448165893555, 'logits/chosen': -9.245057106018066, 'epoch': 1.76}\n",
      "{'loss': 0.4948, 'learning_rate': 1.0931174089068826e-07, 'rewards/chosen': 0.11616430431604385, 'rewards/rejected': -0.39872047305107117, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 0.5148847699165344, 'logps/rejected': -27.917959213256836, 'logps/chosen': -39.30780029296875, 'logits/rejected': -9.369168281555176, 'logits/chosen': -9.205350875854492, 'epoch': 1.78}\n",
      "{'loss': 0.5047, 'learning_rate': 9.919028340080972e-08, 'rewards/chosen': 0.10633915662765503, 'rewards/rejected': -0.36972612142562866, 'rewards/accuracies': 0.890625, 'rewards/margins': 0.4760652482509613, 'logps/rejected': -27.755325317382812, 'logps/chosen': -39.04475402832031, 'logits/rejected': -9.468484878540039, 'logits/chosen': -9.2310209274292, 'epoch': 1.8}\n",
      "{'loss': 0.4898, 'learning_rate': 8.906882591093117e-08, 'rewards/chosen': 0.129595547914505, 'rewards/rejected': -0.39459842443466187, 'rewards/accuracies': 0.878125011920929, 'rewards/margins': 0.5241938829421997, 'logps/rejected': -27.627696990966797, 'logps/chosen': -39.76346206665039, 'logits/rejected': -9.455358505249023, 'logits/chosen': -9.275794982910156, 'epoch': 1.82}\n",
      "{'loss': 0.4865, 'learning_rate': 7.894736842105262e-08, 'rewards/chosen': 0.14011074602603912, 'rewards/rejected': -0.3915875554084778, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 0.5316983461380005, 'logps/rejected': -27.48525619506836, 'logps/chosen': -40.33966827392578, 'logits/rejected': -9.240891456604004, 'logits/chosen': -9.145353317260742, 'epoch': 1.84}\n",
      "{'loss': 0.4992, 'learning_rate': 6.882591093117408e-08, 'rewards/chosen': 0.12400786578655243, 'rewards/rejected': -0.3759429454803467, 'rewards/accuracies': 0.8656250238418579, 'rewards/margins': 0.4999507963657379, 'logps/rejected': -28.396148681640625, 'logps/chosen': -40.189971923828125, 'logits/rejected': -9.306278228759766, 'logits/chosen': -9.13481330871582, 'epoch': 1.86}\n",
      "{'loss': 0.5011, 'learning_rate': 5.8704453441295546e-08, 'rewards/chosen': 0.1229468435049057, 'rewards/rejected': -0.3644794821739197, 'rewards/accuracies': 0.8968750238418579, 'rewards/margins': 0.4874263405799866, 'logps/rejected': -29.054485321044922, 'logps/chosen': -38.527008056640625, 'logits/rejected': -9.33946704864502, 'logits/chosen': -9.217257499694824, 'epoch': 1.88}\n",
      "{'loss': 0.4992, 'learning_rate': 4.8582995951417e-08, 'rewards/chosen': 0.1395987719297409, 'rewards/rejected': -0.3605138659477234, 'rewards/accuracies': 0.890625, 'rewards/margins': 0.5001125931739807, 'logps/rejected': -26.938282012939453, 'logps/chosen': -39.60759735107422, 'logits/rejected': -9.3760347366333, 'logits/chosen': -9.238924026489258, 'epoch': 1.9}\n",
      "{'loss': 0.4837, 'learning_rate': 3.846153846153846e-08, 'rewards/chosen': 0.1497054398059845, 'rewards/rejected': -0.37846869230270386, 'rewards/accuracies': 0.903124988079071, 'rewards/margins': 0.5281740427017212, 'logps/rejected': -27.715662002563477, 'logps/chosen': -39.43539047241211, 'logits/rejected': -9.394889831542969, 'logits/chosen': -9.184568405151367, 'epoch': 1.92}\n",
      "{'loss': 0.5049, 'learning_rate': 2.834008097165992e-08, 'rewards/chosen': 0.10445129871368408, 'rewards/rejected': -0.3824719190597534, 'rewards/accuracies': 0.846875011920929, 'rewards/margins': 0.4869232177734375, 'logps/rejected': -26.315067291259766, 'logps/chosen': -38.37546920776367, 'logits/rejected': -9.395641326904297, 'logits/chosen': -9.230770111083984, 'epoch': 1.94}\n",
      "{'loss': 0.4739, 'learning_rate': 1.8218623481781373e-08, 'rewards/chosen': 0.16618159413337708, 'rewards/rejected': -0.40128588676452637, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 0.5674675703048706, 'logps/rejected': -29.142038345336914, 'logps/chosen': -42.70903396606445, 'logits/rejected': -9.46422004699707, 'logits/chosen': -9.246187210083008, 'epoch': 1.96}\n",
      "{'loss': 0.4931, 'learning_rate': 8.097165991902834e-09, 'rewards/chosen': 0.1284227818250656, 'rewards/rejected': -0.38973483443260193, 'rewards/accuracies': 0.8843749761581421, 'rewards/margins': 0.5181576013565063, 'logps/rejected': -26.882091522216797, 'logps/chosen': -38.51479721069336, 'logits/rejected': -9.558198928833008, 'logits/chosen': -9.389220237731934, 'epoch': 1.98}\n",
      "{'train_runtime': 344.2521, 'train_samples_per_second': 91.828, 'train_steps_per_second': 2.87, 'train_loss': 0.5481572221165244, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=988, training_loss=0.5481572221165244, metrics={'train_runtime': 344.2521, 'train_samples_per_second': 91.828, 'train_steps_per_second': 2.87, 'train_loss': 0.5481572221165244, 'epoch': 2.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Am sa sa sa.', 'Astăzi este luni.', 'e sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa s', 'Sunt o sase de dră.', 'Am adobtat.', 'Acesta a refuzat să spune mai mult.', 'i ai, dle me.', 'Springa a sa sa sa sa sa sa.', 'Sprăta va acţiona în curând.', 'Nu trebuie să apţine în aprovizionarea.']\n",
      "prompt: <translate English to Romanian: I ate the cheese.>, output:Am sa sa sa.\n",
      "prompt: <translate English to Romanian: Today is Monday.>, output:Astăzi este luni.\n",
      "prompt: <translate English to Romanian: Does he speak English?>, output:e sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa sa s\n",
      "prompt: <translate English to Romanian: I'm sort of tired.>, output:Sunt o sase de dră.\n",
      "prompt: <translate English to Romanian: I am indebted to him.>, output:Am adobtat.\n",
      "prompt: <translate English to Romanian: He refused to say more about that.>, output:Acesta a refuzat să spune mai mult.\n",
      "prompt: <translate English to Romanian: Let me in, please.>, output:i ai, dle me.\n",
      "prompt: <translate English to Romanian: Spring is around the corner.>, output:Springa a sa sa sa sa sa sa.\n",
      "prompt: <translate English to Romanian: Spring will arrive there soon.>, output:Sprăta va acţiona în curând.\n",
      "prompt: <translate English to Romanian: You don’t need to apply in advance.>, output:Nu trebuie să apţine în aprovizionarea.\n"
     ]
    }
   ],
   "source": [
    "def translate_batch(batch, model=model, tokenizer=tokenizer):\n",
    "    inputTokens = tokenizer(batch, padding=True, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    outputs = model.generate(input_ids = inputTokens['input_ids'].long(), attention_mask=inputTokens['attention_mask'], max_new_tokens=128)\n",
    "    outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    for i, j in zip(batch, outputs):\n",
    "        print(f\"prompt: <{i}>, output:{j}\")\n",
    "\n",
    "\n",
    "translate_batch(df.prompt.values.tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
